{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758e5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "for dataset_type in [\"Learning_org\", \"Test_org\"]:\n",
    "    results = [[\"filepath\", \"waveform_size\", \"waveform_components\", \"p_idx\", \"s_idx\", \"start_idx\"]]\n",
    "    for fn in glob.glob(f\"data/{dataset_type}/*.npz\"):\n",
    "        data = np.load(fn)\n",
    "        waveform = data[\"wave\"]\n",
    "        waveform_shape = waveform.shape\n",
    "        components = waveform.shape[0]\n",
    "        waveform_size = waveform.shape[1] \n",
    "        pidx = data[\"pidx\"]\n",
    "        sidx = data[\"sidx\"]\n",
    "        if sidx + 500 > 3000:\n",
    "            if pidx - 500 + 3000 > waveform_size:\n",
    "                start_idx = waveform_size - 3000\n",
    "            else:\n",
    "                start_idx = pidx - 500\n",
    "        else:\n",
    "            start_idx = 0\n",
    "        results.append([fn, waveform_size, components, pidx, sidx, start_idx])\n",
    "\n",
    "    with open(f\"data/{dataset_type}/fileinfo.csv\", \"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd75286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4935/4935 [00:02<00:00, 1980.62it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2017.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def modify_data(waveform, pidx, sidx, start_idx):\n",
    "    modified_waveform = waveform[:, start_idx: start_idx+3000]\n",
    "    modified_pidx = pidx - start_idx\n",
    "    modified_sidx = sidx - start_idx\n",
    "    return modified_waveform, modified_pidx, modified_sidx\n",
    "\n",
    "for dataset_type in [\"Learning_org\", \"Test_org\"]:\n",
    "    save_dir = Path(f\"data/{dataset_type.replace('_org', '')}\")\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.read_csv(f\"data/{dataset_type}/fileinfo.csv\")\n",
    "    # print(df)\n",
    "    for (fn, start_idx) in tqdm(df[[\"filepath\", \"start_idx\"]].values, total=len(df)):\n",
    "        data = np.load(fn)\n",
    "        waveform = data[\"wave\"]\n",
    "        pidx = data[\"pidx\"]\n",
    "        sidx = data[\"sidx\"]\n",
    "        modified_waveform, modified_pidx, modified_sidx = modify_data(waveform, pidx, sidx, start_idx)\n",
    "        np.savez(\n",
    "            fn.replace(\"_org\", \"\"), \n",
    "            wave=modified_waveform, \n",
    "            pidx=modified_pidx,\n",
    "            sidx=modified_sidx\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f112b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 4441/4441 [01:07<00:00, 65.34it/s]\n",
      "Processing val: 100%|██████████| 494/494 [00:07<00:00, 65.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 39969 original + augmented training samples to unet_snr/datasets/train\n",
      "✅ Saved 4446 validation samples to unet_snr/datasets/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from obspy import Stream, Trace, UTCDateTime\n",
    "from tqdm import tqdm\n",
    "import seisbench.models as sbm\n",
    "\n",
    "SAMPLE_RATE = 100\n",
    "WIN_LENGTH = 30\n",
    "HOP_LENGTH = 15\n",
    "N_FFT = 60\n",
    "DURATION = 30 * SAMPLE_RATE\n",
    "EPS = 1e-8\n",
    "\n",
    "np.random.seed(5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === DeepDenoiser モデルロード ===\n",
    "model = sbm.DeepDenoiser.from_pretrained(\"original\")\n",
    "\n",
    "# === ディレクトリ設定 ===\n",
    "input_dir = \"data/Learning\"\n",
    "output_root = Path(\"unet_snr/datasets\")\n",
    "train_dir = output_root / \"train\"\n",
    "val_dir = output_root / \"val\"\n",
    "train_dir.mkdir(parents=True, exist_ok=True)\n",
    "val_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "channels = [\"UD\", \"NS\", \"EW\"]\n",
    "\n",
    "\n",
    "def compute_stft_with_phase_rotation(wave):\n",
    "    stft = torch.stft(\n",
    "        torch.from_numpy(wave),\n",
    "        n_fft=N_FFT,\n",
    "        return_complex=True,\n",
    "        win_length=WIN_LENGTH,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        window=torch.hann_window(WIN_LENGTH),\n",
    "        pad_mode=\"constant\",\n",
    "        normalized=False,\n",
    "    )\n",
    "\n",
    "    stft = (2 / WIN_LENGTH) * stft\n",
    "\n",
    "    return stft\n",
    "\n",
    "def process_wave(wave):\n",
    "    stft = compute_stft_with_phase_rotation(wave)\n",
    "    stft_real_img = torch.stack([stft.real, stft.imag], dim=0)  # shape: [2, F, T]\n",
    "    return stft_real_img\n",
    "\n",
    "def create_mask(wave_stft, denoised_stft, pidx):\n",
    "    stft_abs = torch.abs(wave_stft[0] + wave_stft[1] * 1j)\n",
    "    denoised_abs = torch.abs(denoised_stft[0] + denoised_stft[1] * 1j)\n",
    "    mask = denoised_abs / (stft_abs + EPS)\n",
    "    mask = torch.clip(mask, 0, 1)\n",
    "    mask[:, :int(pidx/HOP_LENGTH)-1] = 0.01\n",
    "    return mask\n",
    "\n",
    "# === ObsPy変換関数 ===\n",
    "def convert_ndarry_stream(data, time_str, station_name, sampling_rate=100):\n",
    "    year = 2000 + int(time_str[:2])\n",
    "    month, day = int(time_str[2:4]), int(time_str[4:6])\n",
    "    hour, minute, second = int(time_str[7:9]), int(time_str[9:11]), int(time_str[11:13])\n",
    "    utc_time = UTCDateTime(year, month, day, hour, minute, second)\n",
    "    channels = [\"UD\", \"NS\", \"EW\"]\n",
    "    stream = Stream()\n",
    "    for i, ch in enumerate(channels):\n",
    "        trace = Trace(data=data[i])\n",
    "        trace.stats.update({\n",
    "            \"sampling_rate\": sampling_rate,\n",
    "            \"starttime\": utc_time,\n",
    "            \"network\": \"MeSO-net\",\n",
    "            \"station\": station_name,\n",
    "            \"location\": \"\",\n",
    "            \"channel\": ch,\n",
    "        })\n",
    "        stream.append(trace)\n",
    "    return stream\n",
    "\n",
    "def convert_stream_to_ndarray(stream, channel_order=[\"UD\", \"NS\", \"EW\"]):\n",
    "    traces = []\n",
    "    for ch in channel_order:\n",
    "        tr = stream.select(channel=ch)\n",
    "        if len(tr) == 0:\n",
    "            raise ValueError(f\"Channel {ch} not found in the stream.\")\n",
    "        traces.append(tr[0].data)\n",
    "    return np.stack(traces)\n",
    "\n",
    "# === ファイル一覧取得 & 分割 ===\n",
    "npz_files = sorted(glob.glob(os.path.join(input_dir, \"*.npz\")))\n",
    "train_files, val_files = train_test_split(npz_files, test_size=0.1, random_state=42)\n",
    "\n",
    "# === 処理関数（ノイズ拡張あり）===\n",
    "def process_and_save(file_list, out_dir, add_noise=True, num_augments=2):\n",
    "    for fn in tqdm(file_list, desc=f\"Processing {out_dir.name}\"):\n",
    "        data = np.load(fn)\n",
    "        wave = data[\"wave\"].astype(np.float32)  # (3, 3000)\n",
    "        wave -= np.mean(wave, axis=1, keepdims=True)\n",
    "        pidx = int(data[\"pidx\"])\n",
    "        sidx = int(data[\"sidx\"])\n",
    "\n",
    "        try:\n",
    "            time_str, station_name = os.path.basename(fn).replace(\".npz\", \"\").split(\"_\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Skipping invalid filename {fn}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            original_stream = convert_ndarry_stream(wave, time_str, station_name)\n",
    "            denoised_stream = model.annotate(original_stream)\n",
    "\n",
    "            denoised = convert_stream_to_ndarray(\n",
    "                denoised_stream,\n",
    "                channel_order=[\"DeepDenoiser_UD\", \"DeepDenoiser_NS\", \"DeepDenoiser_EW\"]\n",
    "            ).astype(np.float32)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to denoise {fn}: {e}\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        for i in range(3):\n",
    "            # 元データ保存\n",
    "            tmp_wave = wave[i]\n",
    "            tmp_denoised = denoised[i]\n",
    "            stft_real_img = process_wave(tmp_wave)\n",
    "            de_stft_real_img = process_wave(tmp_denoised)\n",
    "            mask = create_mask(stft_real_img, de_stft_real_img, pidx)\n",
    "            base_name = os.path.basename(fn).replace(\".npz\", f\"_{channels[i]}\")\n",
    "\n",
    "            save_dict = {\n",
    "                \"spec\": stft_real_img,\n",
    "                \"de_spec\": de_stft_real_img,\n",
    "                \"mask\": mask,\n",
    "                \"pidx\": pidx,\n",
    "                \"sidx\": sidx,\n",
    "                \"name\": f\"{base_name}.pt\"\n",
    "            }\n",
    "            torch.save(save_dict, out_dir / save_dict[\"name\"])\n",
    "\n",
    "            # === ノイズ付き拡張 ===\n",
    "            if add_noise:\n",
    "                for aug_id in range(num_augments):\n",
    "                    noise_strength = np.random.uniform(0.2, 0.5)\n",
    "                    std_per_channel = np.std(tmp_wave)\n",
    "                    noise = np.random.normal(\n",
    "                        scale=std_per_channel * noise_strength, \n",
    "                        size=tmp_wave.shape\n",
    "                    ).astype(np.float32)\n",
    "                    noisy_wave = tmp_wave + noise\n",
    "                    noisy_wave -= np.mean(noisy_wave)\n",
    "                    noisy_stft_real_img = process_wave(noisy_wave)\n",
    "                    mask_aug = create_mask(noisy_stft_real_img, de_stft_real_img, pidx)\n",
    "\n",
    "                    aug_dict = {\n",
    "                        \"spec\": noisy_stft_real_img,\n",
    "                        \"de_spec\": de_stft_real_img,\n",
    "                        \"mask\": mask_aug,\n",
    "                        \"pidx\": pidx,\n",
    "                        \"sidx\": sidx,\n",
    "                        \"name\": f\"{base_name}_aug{aug_id}.pt\"\n",
    "                    }\n",
    "                    torch.save(aug_dict, out_dir / aug_dict[\"name\"])\n",
    "\n",
    "# === 実行 ===\n",
    "num_augments = 2\n",
    "add_noise = True\n",
    "total_per_file = 3 * (1 + num_augments if add_noise else 1)\n",
    "process_and_save(train_files, train_dir, add_noise=add_noise, num_augments=num_augments)\n",
    "process_and_save(val_files, val_dir, add_noise=add_noise, num_augments=num_augments)\n",
    "\n",
    "print(f\"✅ Saved {len(train_files) * total_per_file} original + augmented training samples to {train_dir}\")\n",
    "print(f\"✅ Saved {len(val_files) * total_per_file} validation samples to {val_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb31c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geosciai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
