{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EYrltldYH_Tg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from obspy import Stream, Trace, UTCDateTime\n",
    "import seisbench.models as sbm\n",
    "import csv\n",
    "from model import UNet2D\n",
    "from scipy.signal import ShortTimeFFT\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0IvjXRIHh2S"
   },
   "outputs": [],
   "source": [
    "# === パラメータ ===\n",
    "SAMPLE_RATE = 100\n",
    "WIN_LENGTH = 30\n",
    "HOP_LENGTH = 15\n",
    "N_FFT = 60\n",
    "EPS = 1e-8\n",
    "\n",
    "SFT = ShortTimeFFT(\n",
    "    win=np.hanning(WIN_LENGTH),\n",
    "    hop=HOP_LENGTH,\n",
    "    fs=SAMPLE_RATE,\n",
    "    fft_mode=\"onesided2X\",\n",
    "    mfft=N_FFT,\n",
    "    scale_to=\"magnitude\",\n",
    ")\n",
    "\n",
    "# === モデル読み込み ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet2D()\n",
    "model.load_state_dict(torch.load(\"model/best_model.pt\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def denoise(model, deepdenoiser, original_stream):\n",
    "    deepdenoised_stream = deepdenoiser.annotate(original_stream)\n",
    "    deepdenoised = convert_stream_to_ndarray(deepdenoised_stream, channel_order=[\"DeepDenoiser_UD\", \"DeepDenoiser_NS\", \"DeepDenoiser_EW\"])\n",
    "    deepdenoised_abs = np.abs(SFT.stft(deepdenoised))\n",
    "\n",
    "    original = convert_stream_to_ndarray(original_stream)  # shape: [3, N]\n",
    "    spec_list = []\n",
    "    orig_mag_list = []\n",
    "    denoised_mag_list = []\n",
    "\n",
    "    for i in range(3):\n",
    "        Zxx = SFT.stft(original[i])\n",
    "        real = np.real(Zxx)\n",
    "        imag = np.imag(Zxx)\n",
    "        spec_list.append(real)\n",
    "        spec_list.append(imag)\n",
    "        orig_mag_list.append(np.abs(Zxx))\n",
    "\n",
    "    spec_array = np.stack(spec_list, axis=0).astype(np.float32)  # shape: [6, F, T]\n",
    "\n",
    "    for i in range(3):\n",
    "        real = spec_array[2*i]\n",
    "        imag = spec_array[2*i+1]\n",
    "        \n",
    "        mean_real = np.mean(real)\n",
    "        std_real = np.std(real) + 1e-6\n",
    "        spec_array[2*i] = (real - mean_real) / std_real\n",
    "\n",
    "        mean_imag = np.mean(imag)\n",
    "        std_imag = np.std(imag) + 1e-6\n",
    "        spec_array[2*i+1] = (imag - mean_imag) / std_imag\n",
    "\n",
    "    # 推論\n",
    "    spec_tensor = torch.from_numpy(spec_array).float().unsqueeze(0).to(device)  # [1, 6, F, T]\n",
    "    with torch.no_grad():\n",
    "        pred_mask = model(spec_tensor).squeeze(0).cpu().numpy()  # [3, F, T]\n",
    "\n",
    "    # real・imag にマスクをかけて再構成\n",
    "    denoised = []\n",
    "    for i in range(3):\n",
    "        Zxx = SFT.stft(original[i])\n",
    "        denoised_Zxx = Zxx * pred_mask[i]\n",
    "        wav = SFT.istft(denoised_Zxx, k1=3000)\n",
    "        denoised_mag_list.append(np.abs(denoised_Zxx))\n",
    "\n",
    "        denoised.append(wav.astype(np.float32))\n",
    "\n",
    "    return np.stack(denoised), np.array(orig_mag_list), np.array(denoised_mag_list), deepdenoised, deepdenoised_abs  # shape: [3, N]\n",
    "\n",
    "\n",
    "# Utility functions\n",
    "def convert_ndarry_stream(data, time_str, station_name, sampling_rate=100):\n",
    "    \"\"\"\n",
    "    Convert a 2D NumPy array of waveform data into an ObsPy Stream object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        2D array of shape (3, N), where N is the number of samples for each component (UD, NS, EW).\n",
    "    time_str : str\n",
    "        Start time string in the format 'yymmdd_HHMMSS' (e.g., '150323_141948').\n",
    "    station_name : str\n",
    "        Station name to be assigned to each trace.\n",
    "    sampling_rate : float, optional\n",
    "        Sampling rate in Hz. Default is 100 Hz.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stream : obspy.Stream\n",
    "        ObsPy Stream object containing three Traces with appropriate metadata.\n",
    "    \"\"\"\n",
    "    year = 2000 + int(time_str[:2])\n",
    "    month, day = int(time_str[2:4]), int(time_str[4:6])\n",
    "    hour, minute, second = int(time_str[7:9]), int(time_str[9:11]), int(time_str[11:13])\n",
    "    utc_time = UTCDateTime(year, month, day, hour, minute, second)\n",
    "\n",
    "    channels = [\"UD\", \"NS\", \"EW\"]\n",
    "    stream = Stream()\n",
    "    for i, ch in enumerate(channels):\n",
    "        trace = Trace(data=data[i, :])\n",
    "        trace.stats.update({\n",
    "            \"sampling_rate\": sampling_rate,\n",
    "            \"starttime\": utc_time,\n",
    "            \"network\": \"MeSO-net\",\n",
    "            \"station\": station_name,\n",
    "            \"location\": \"\",\n",
    "            \"channel\": ch,\n",
    "        })\n",
    "        stream.append(trace)\n",
    "    return stream\n",
    "\n",
    "def convert_stream_to_ndarray(stream, channel_order=[\"UD\", \"NS\", \"EW\"]):\n",
    "    \"\"\"\n",
    "    Convert ObsPy Stream to ndarray of shape (samples, channels).\n",
    "\n",
    "    Parameters:\n",
    "        stream (obspy.Stream): Stream object containing 3 components.\n",
    "        channel_order (list): Order of channels to extract, default is [\"UD\", \"NS\", \"EW\"].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of shape (3, n_samples)\n",
    "    \"\"\"\n",
    "    traces = []\n",
    "    for ch in channel_order:\n",
    "        tr = stream.select(channel=ch)\n",
    "        if len(tr) == 0:\n",
    "            raise ValueError(f\"Channel {ch} not found in the stream.\")\n",
    "        traces.append(tr[0].data)\n",
    "\n",
    "    # Stack and transpose to shape (samples, channels)\n",
    "    data = np.stack(traces)\n",
    "    return data\n",
    "\n",
    "def calc_snr(signal, noise):\n",
    "    \"\"\"\n",
    "    Calculate signal-to-noise ratio (SNR) in decibels (dB).\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    signal : np.ndarray\n",
    "        Array containing the signal portion.\n",
    "    noise : np.ndarray\n",
    "        Array containing the noise portion.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    float\n",
    "        SNR value in dB.\n",
    "    \"\"\"\n",
    "    return 10 * np.log10(np.std(signal) / np.std(noise))\n",
    "\n",
    "def calc_cc(a, b):\n",
    "    \"\"\"\n",
    "    Calculate the Pearson correlation coefficient between two signals.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    a : np.ndarray\n",
    "        First signal.\n",
    "    b : np.ndarray\n",
    "        Second signal.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    float\n",
    "        Correlation coefficient between a and b (range: -1 to 1).\n",
    "    \"\"\"\n",
    "    return np.corrcoef(a, b)[0, 1]\n",
    "\n",
    "def zscore(data):\n",
    "    \"\"\"\n",
    "    Normalize each channel using z-score normalization (zero mean, unit variance).\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        2D array of shape (channels, time), e.g., (3, N).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Z-score normalized data with the same shape.\n",
    "    \"\"\"\n",
    "    mean = np.mean(data, axis=1, keepdims=True)\n",
    "    std = np.std(data, axis=1, keepdims=True)\n",
    "    normalized_data = (data - mean) / std\n",
    "    return normalized_data\n",
    "\n",
    "def calc_loss(data1, data2, p_onset, s_onset, sf=100):\n",
    "\n",
    "    '''\n",
    "    Calculate a loss value based on signal-to-noise ratio (SNR) and correlation coefficients (CC)\n",
    "    between original and denoised seismic waveform data for P-wave, S-wave, and noise segments.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data1 (Original wave) : np.ndarray\n",
    "        Original waveform data of shape (3, N), where N is the number of time steps.\n",
    "    data2 (Denoised wave) : np.ndarray\n",
    "        Denoised waveform data of shape (3, N), corresponding to data1.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    loss : float\n",
    "        Averaged loss across 3 channels, combining SNR and CC values.\n",
    "    P_SNR : float\n",
    "        Averaged P-wave SNR after denoising.\n",
    "    S_SNR : float\n",
    "        Averaged S-wave SNR after denoising.\n",
    "    P_CC : float\n",
    "        Averaged correlation coefficient between original and denoised P-wave signals.\n",
    "    s_cc : float\n",
    "        Averaged correlation coefficient between original and denoised S-wave signals.\n",
    "    n_cc : float\n",
    "        Averaged correlation coefficient between original and denoised noise segments.\n",
    "    '''\n",
    "\n",
    "    p_snrs = []\n",
    "    s_snrs = []\n",
    "    p_ccs = []\n",
    "    s_ccs = []\n",
    "    n_ccs = []\n",
    "\n",
    "    loss = []\n",
    "\n",
    "    for ch in [0,1,2]:\n",
    "        orig_data = data1[ch,:]\n",
    "        den_data = data2[ch,:]\n",
    "\n",
    "        signal_p = orig_data[p_onset : p_onset+sf*5]\n",
    "        noise_p = orig_data[p_onset-sf*5 : p_onset]\n",
    "\n",
    "        signal_p_deno = den_data[p_onset : p_onset+sf*5]\n",
    "        noise_p_deno = den_data[p_onset-sf*5 : p_onset]\n",
    "\n",
    "        signal_s = orig_data[s_onset : s_onset+sf*5]\n",
    "        signal_s_deno = den_data[s_onset : s_onset+sf*5]\n",
    "\n",
    "        snr_p_orig = calc_snr(signal_p, noise_p)\n",
    "        snr_s_orig = calc_snr(signal_s, noise_p)\n",
    "\n",
    "        snr_p_deno = calc_snr(signal_p_deno, noise_p_deno)\n",
    "        snr_s_deno = calc_snr(signal_s_deno, noise_p_deno)\n",
    "\n",
    "        cc_n = calc_cc(noise_p, noise_p_deno)\n",
    "        cc_p = calc_cc(signal_p, signal_p_deno)\n",
    "        cc_s = calc_cc(signal_s, signal_s_deno)\n",
    "\n",
    "        loss_ch = (snr_p_deno + snr_s_deno) * cc_p * cc_s * cc_n\n",
    "\n",
    "        p_snrs.append(snr_p_deno)\n",
    "        s_snrs.append(snr_s_deno)\n",
    "\n",
    "        p_ccs.append(cc_p)\n",
    "        s_ccs.append(cc_s)\n",
    "        n_ccs.append(cc_n)\n",
    "\n",
    "        loss.append(loss_ch)\n",
    "\n",
    "    return np.mean(loss), p_snrs, s_snrs, p_ccs, s_ccs, n_ccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16135,
     "status": "ok",
     "timestamp": 1743300782349,
     "user": {
      "displayName": "長尾大道",
      "userId": "00877909077498074599"
     },
     "user_tz": -540
    },
    "id": "qcwsDOt6IFR0",
    "outputId": "3632f04b-dca7-45bb-86e8-d6b0a8020592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [12:07<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss = 18.343057021001176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained denoising model\n",
    "deepdenoiser = sbm.DeepDenoiser.from_pretrained(\"original\")\n",
    "\n",
    "\n",
    "\n",
    "model_type = \"CBAM\"\n",
    "total_loss = 0\n",
    "\n",
    "# Prepare data\n",
    "files = sorted(glob.glob('data/Test/*'))     # 適切なパスを設定\n",
    "\n",
    "print(len(files))\n",
    "\n",
    "with open(f'reports/{model_type}_loss_results.csv', 'w', newline='') as csvfile:   # 適切なパスを設定\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # headder\n",
    "    writer.writerow(['FileName', 'LOSS', 'UD_P_SNR', 'UD_S_SNR', 'UD_P_CC', 'UD_S_CC', 'UD_N_CC', 'NS_P_SNR', 'NS_S_SNR', 'NS_P_CC', 'NS_S_CC', 'NS_N_CC', 'EW_P_SNR', 'EW_S_SNR', 'EW_P_CC', 'EW_S_CC', 'EW_N_CC'])\n",
    "\n",
    "    for fn in tqdm(files, total=len(files)):\n",
    "      data = np.load(fn)\n",
    "      wave, p_onset, s_onset = data['wave'], data['pidx'], data['sidx']\n",
    "      time_str, station_name = os.path.basename(fn).replace('.npz', '').split('_')\n",
    "\n",
    "      # Create ObsPy Stream\n",
    "      original_stream = convert_ndarry_stream(wave-np.mean(wave, axis=1, keepdims=True), time_str, station_name)\n",
    "\n",
    "      denoised, orig_abs, denoised_abs, deepdenoised, deepdenoised_abs = denoise(model, deepdenoiser, original_stream)\n",
    "      original = convert_stream_to_ndarray(original_stream, channel_order=[\"UD\", \"NS\", \"EW\"])\n",
    "\n",
    "      if model_type == \"deepdenoiser\":\n",
    "          denoised = deepdenoised\n",
    "    #   elif model_type == \"CBAM\":\n",
    "    #       titles = [\"UD\", \"NS\", \"EW\"]\n",
    "    #       fig, axes = plt.subplots(6, 3, figsize=(16, 20))\n",
    "\n",
    "    #       for i in range(3):\n",
    "    #           axes[0, i].set_title(f\"Original {titles[i]}\")\n",
    "    #           axes[0, i].plot(np.linspace(0, 30, 3000), original[i])\n",
    "    #           axes[0, i].set_xlim(0, 30)\n",
    "    #           axes[1, i].imshow(np.log10(orig_abs[i] + 1e-8), extent=[0, 30, 0, 50], aspect=\"auto\", origin=\"lower\")\n",
    "\n",
    "    #           axes[2, i].set_title(f\"Denoised {titles[i]}\")\n",
    "    #           axes[2, i].plot(np.linspace(0, 30, 3000), denoised[i])\n",
    "    #           axes[2, i].set_xlim(0, 30)\n",
    "    #           axes[3, i].imshow(np.log10(denoised_abs[i] + 1e-8), extent=[0, 30, 0, 50], aspect=\"auto\", origin=\"lower\", vmin=0, vmax=1)\n",
    "\n",
    "    #           axes[4, i].set_title(f\"DeepDenoiser {titles[i]}\")\n",
    "    #           axes[4, i].plot(np.linspace(0, 30, 3000),deepdenoised[i])\n",
    "    #           axes[4, i].set_xlim(0, 30)\n",
    "    #           axes[5, i].imshow(np.log10(deepdenoised_abs[i] + 1e-8), extent=[0, 30, 0, 50], aspect=\"auto\", origin=\"lower\", vmin=0, vmax=1)\n",
    "\n",
    "\n",
    "    #       # 縦の間隔を広げる\n",
    "    #       plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "    #       # ファイル名を動的に生成して保存\n",
    "    #       fig_name = f\"figures/{os.path.basename(fn).replace('.npz', '')}_comparison.png\"\n",
    "    #       os.makedirs(\"figures\", exist_ok=True)\n",
    "    #       plt.savefig(fig_name, dpi=300, bbox_inches='tight')\n",
    "    #       plt.close()\n",
    "          \n",
    "      \n",
    "  \n",
    "\n",
    "      loss, p_snrs, s_snrs, p_ccs, s_ccs, n_ccs = calc_loss(original, denoised, p_onset, s_onset)\n",
    "\n",
    "      writer.writerow([os.path.basename(fn),\n",
    "                       loss,\n",
    "                       p_snrs[0], s_snrs[0], p_ccs[0], s_ccs[0], n_ccs[0],\n",
    "                       p_snrs[1], s_snrs[1], p_ccs[1], s_ccs[1], n_ccs[1],\n",
    "                       p_snrs[2], s_snrs[2], p_ccs[2], s_ccs[2], n_ccs[2]])\n",
    "\n",
    "      print(os.path.basename(fn), loss, p_snr, s_snr, P_CC, s_cc, n_cc)\n",
    "\n",
    "      total_loss += loss\n",
    "\n",
    "print(f'Total Loss = {total_loss/(len(files))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59e1Se_HHnTx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOSS</th>\n",
       "      <th>UD_P_SNR</th>\n",
       "      <th>UD_S_SNR</th>\n",
       "      <th>UD_P_CC</th>\n",
       "      <th>UD_S_CC</th>\n",
       "      <th>UD_N_CC</th>\n",
       "      <th>NS_P_SNR</th>\n",
       "      <th>NS_S_SNR</th>\n",
       "      <th>NS_P_CC</th>\n",
       "      <th>NS_S_CC</th>\n",
       "      <th>NS_N_CC</th>\n",
       "      <th>EW_P_SNR</th>\n",
       "      <th>EW_S_SNR</th>\n",
       "      <th>EW_P_CC</th>\n",
       "      <th>EW_S_CC</th>\n",
       "      <th>EW_N_CC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.580729</td>\n",
       "      <td>15.804465</td>\n",
       "      <td>16.050645</td>\n",
       "      <td>0.959767</td>\n",
       "      <td>0.977638</td>\n",
       "      <td>0.354823</td>\n",
       "      <td>19.502171</td>\n",
       "      <td>24.291604</td>\n",
       "      <td>0.947203</td>\n",
       "      <td>0.984400</td>\n",
       "      <td>0.375697</td>\n",
       "      <td>19.163827</td>\n",
       "      <td>23.676196</td>\n",
       "      <td>0.945870</td>\n",
       "      <td>0.983163</td>\n",
       "      <td>0.376412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.542047</td>\n",
       "      <td>6.295686</td>\n",
       "      <td>6.991246</td>\n",
       "      <td>0.068830</td>\n",
       "      <td>0.042132</td>\n",
       "      <td>0.180425</td>\n",
       "      <td>6.867532</td>\n",
       "      <td>7.268912</td>\n",
       "      <td>0.077355</td>\n",
       "      <td>0.034436</td>\n",
       "      <td>0.217081</td>\n",
       "      <td>6.573299</td>\n",
       "      <td>7.045687</td>\n",
       "      <td>0.073924</td>\n",
       "      <td>0.036073</td>\n",
       "      <td>0.217266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.372592</td>\n",
       "      <td>-1.348372</td>\n",
       "      <td>-3.355258</td>\n",
       "      <td>0.424526</td>\n",
       "      <td>0.570517</td>\n",
       "      <td>0.091079</td>\n",
       "      <td>-1.535250</td>\n",
       "      <td>0.789417</td>\n",
       "      <td>0.487167</td>\n",
       "      <td>0.522748</td>\n",
       "      <td>0.079339</td>\n",
       "      <td>-0.575507</td>\n",
       "      <td>1.164487</td>\n",
       "      <td>0.585403</td>\n",
       "      <td>0.628441</td>\n",
       "      <td>0.102688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.182358</td>\n",
       "      <td>11.819522</td>\n",
       "      <td>11.025746</td>\n",
       "      <td>0.952316</td>\n",
       "      <td>0.976396</td>\n",
       "      <td>0.234248</td>\n",
       "      <td>15.217295</td>\n",
       "      <td>19.705909</td>\n",
       "      <td>0.932430</td>\n",
       "      <td>0.984817</td>\n",
       "      <td>0.217800</td>\n",
       "      <td>14.901349</td>\n",
       "      <td>19.004151</td>\n",
       "      <td>0.928401</td>\n",
       "      <td>0.983647</td>\n",
       "      <td>0.215934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.775206</td>\n",
       "      <td>15.299281</td>\n",
       "      <td>15.784638</td>\n",
       "      <td>0.985888</td>\n",
       "      <td>0.992890</td>\n",
       "      <td>0.302857</td>\n",
       "      <td>19.781446</td>\n",
       "      <td>24.432595</td>\n",
       "      <td>0.976593</td>\n",
       "      <td>0.996120</td>\n",
       "      <td>0.293704</td>\n",
       "      <td>19.163641</td>\n",
       "      <td>23.669145</td>\n",
       "      <td>0.978109</td>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.295649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.222834</td>\n",
       "      <td>19.306071</td>\n",
       "      <td>20.381430</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>0.413846</td>\n",
       "      <td>23.428479</td>\n",
       "      <td>29.171625</td>\n",
       "      <td>0.995210</td>\n",
       "      <td>0.998819</td>\n",
       "      <td>0.479068</td>\n",
       "      <td>22.895944</td>\n",
       "      <td>28.135418</td>\n",
       "      <td>0.995423</td>\n",
       "      <td>0.998634</td>\n",
       "      <td>0.486489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.169810</td>\n",
       "      <td>38.856273</td>\n",
       "      <td>40.124755</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.977706</td>\n",
       "      <td>45.011053</td>\n",
       "      <td>48.377485</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.971214</td>\n",
       "      <td>42.478752</td>\n",
       "      <td>44.091229</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.969519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOSS    UD_P_SNR    UD_S_SNR     UD_P_CC     UD_S_CC     UD_N_CC  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean    12.580729   15.804465   16.050645    0.959767    0.977638    0.354823   \n",
       "std      6.542047    6.295686    6.991246    0.068830    0.042132    0.180425   \n",
       "min      0.372592   -1.348372   -3.355258    0.424526    0.570517    0.091079   \n",
       "25%      8.182358   11.819522   11.025746    0.952316    0.976396    0.234248   \n",
       "50%     10.775206   15.299281   15.784638    0.985888    0.992890    0.302857   \n",
       "75%     15.222834   19.306071   20.381430    0.997365    0.998668    0.413846   \n",
       "max     44.169810   38.856273   40.124755    0.999896    0.999901    0.977706   \n",
       "\n",
       "         NS_P_SNR    NS_S_SNR     NS_P_CC     NS_S_CC     NS_N_CC    EW_P_SNR  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean    19.502171   24.291604    0.947203    0.984400    0.375697   19.163827   \n",
       "std      6.867532    7.268912    0.077355    0.034436    0.217081    6.573299   \n",
       "min     -1.535250    0.789417    0.487167    0.522748    0.079339   -0.575507   \n",
       "25%     15.217295   19.705909    0.932430    0.984817    0.217800   14.901349   \n",
       "50%     19.781446   24.432595    0.976593    0.996120    0.293704   19.163641   \n",
       "75%     23.428479   29.171625    0.995210    0.998819    0.479068   22.895944   \n",
       "max     45.011053   48.377485    0.999876    0.999875    0.971214   42.478752   \n",
       "\n",
       "         EW_S_SNR     EW_P_CC     EW_S_CC     EW_N_CC  \n",
       "count  500.000000  500.000000  500.000000  500.000000  \n",
       "mean    23.676196    0.945870    0.983163    0.376412  \n",
       "std      7.045687    0.073924    0.036073    0.217266  \n",
       "min      1.164487    0.585403    0.628441    0.102688  \n",
       "25%     19.004151    0.928401    0.983647    0.215934  \n",
       "50%     23.669145    0.978109    0.995575    0.295649  \n",
       "75%     28.135418    0.995423    0.998634    0.486489  \n",
       "max     44.091229    0.999880    0.999916    0.969519  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"mine_loss_results.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "geosciai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
